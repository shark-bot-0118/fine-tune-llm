# Development Note

このファイルは、LoRAファインチューニングプロジェクトの開発過程で得られた知見、制約、課題などを記録します。

## 開発環境での検証結果

### 動作確認済み環境
- Python 3.12
- PyTorch 2.1+
- Apple Silicon (Mac Book pro m3)
- メモリ(ユニファイドメモリ): 32GB 

### 推奨モデルサイズ
- 1Bパラメータ: おそらく高スペックPCでなくとも動作可能
- 4Bパラメータ: Apple Silicon (Mac Book pro m3)にて動作

## 制約・注意点

### メモリ制約
トレーニングモデルのサイズによって必要とされるメモリ量が大きく変動  
下記に使用メモリの目安を記載(実測値) ※実行環境やトレーニングパラメータ、トレーニングデータ量によって大きく変動します
- **Gemma-3-1b-it**: 10GB程度
- **Gemma-3-4b-it**: 25GB程度
  
### モデル固有の制約
- **Gemma 3**: transformers>=4.46.0必須
- **tokenizer.model**: 自動生成されない場合は手動ダウンロード必要
- **EOS token**: モデルによって設定が異なる

### GGUF変換の制約
- **llama.cpp**: 必ずCMakeでビルド推奨
- **量子化**: F16→Q4への変換で2-3GB一時的にメモリ使用
- **Metal/CUDA**: 環境に応じて最適化フラグが必要

## コメント

LLMをトレーニングする場合は、現在の実行環境とモデルの性質を必ず確認してください  
特に実行環境がNvidiaかMacかで大きく変わってきます  
Macの場合はdfloat16が安定していないのか同じパラメータ、データ、モデルでも実行結果に差異があるように感じます  
トレーニングを始める際、当然ですがトレーニングデータとモデルサイズによって適切なトレーニングパラメータを設定しなければなりません  
これが最も骨が折れる作業で、はじめはひたすらトライアンドエラーの繰り返しでした  
データが同じでもパラメータ設定が悪いと生成する回答が崩壊したり、期待通りの動きをしなかったりするのでFine-Tuningで最も苦労するポイントはおそらくパラメータ設定かと思います  
とりわけデータ量が少ない場合(400程度)、LLMの出力が不安定になる傾向があるので、データ量は極力多くした方が良いです  
最終的には400程度でもある程度機能するような設定を見つけましたが、モデルによって挙動結果は大きく異なるのでとりあえずの設定値はないような気がします(当たり前ですが)  
後述の理由であまり参考にならないかもしれませんが、以下に実際にトレーニングにかかった時間を記載します

- **Gemma-3-1b-it**: 10分
- **Gemma-3-4b-it**: 8時間  
※データ量:400件

**Gemma-3-4b-it**でのトレーニング時間が異常に長いですが、こちらはキャッシュクリアしておらず、裏で作業をしていたのでこれほどかかったものかと思います...
